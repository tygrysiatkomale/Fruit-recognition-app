{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-25T19:22:13.590957Z",
     "start_time": "2025-03-25T19:22:09.270254Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "# import os\n",
    "\n",
    "# Wykrycie dostępności GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T19:34:02.251167Z",
     "start_time": "2025-03-25T19:34:02.231694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dir = \"fruits_generalization_test/test\"\n",
    "valid_dir = \"fruits_generalization_test/val\"\n",
    "test_dir  = \"fruits_generalization_test/test\""
   ],
   "id": "8d0daf8154a0f05e",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T19:34:03.806971Z",
     "start_time": "2025-03-25T19:34:03.788544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((100, 100)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),  # mean (R,G,B)\n",
    "                         (0.5, 0.5, 0.5))  # std  (R,G,B)\n",
    "])\n",
    "\n",
    "# Zbiór walidacyjny / testowy zwykle bez augmentacji, tylko normalizacja\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((100, 100)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                         (0.5, 0.5, 0.5))\n",
    "])"
   ],
   "id": "661613acfd3a0715",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T19:34:07.533154Z",
     "start_time": "2025-03-25T19:34:07.489994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Zbiór treningowy\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transforms)\n",
    "# Zbiór walidacyjny\n",
    "valid_dataset = datasets.ImageFolder(root=valid_dir, transform=test_transforms)\n",
    "# Zbiór testowy\n",
    "test_dataset  = datasets.ImageFolder(root=test_dir,  transform=test_transforms)"
   ],
   "id": "caeb00450fb94d79",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T19:34:08.217090Z",
     "start_time": "2025-03-25T19:34:08.201053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Liczba klas\n",
    "num_classes = len(train_dataset.classes)\n",
    "print(\"Liczba klas:\", num_classes)\n",
    "print(\"Klasy (index -> nazwa):\", train_dataset.class_to_idx)"
   ],
   "id": "6f105424922468d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba klas: 16\n",
      "Klasy (index -> nazwa): {'Apple': 0, 'Banana 3': 1, 'Beans 1': 2, 'Blackberry': 3, 'Cabbage': 4, 'Cactus fruit green 1': 5, 'Cactus fruit red 1': 6, 'Caju seed 1': 7, 'Cherry Wax not rippen 1': 8, 'Cucumber': 9, 'Gooseberry 1': 10, 'Pear': 11, 'Pistachio 1': 12, 'Zucchini': 13, 'carrot_1': 14, 'eggplant_long_1': 15}\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T19:34:09.172524Z",
     "start_time": "2025-03-25T19:34:09.136914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 100 -> 50\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 50 -> 25\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)   # 25 -> ~12\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 12 * 12, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN(num_classes).to(device)\n",
    "print(model)"
   ],
   "id": "ed440f6452076193",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=18432, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=16, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T19:34:10.412302Z",
     "start_time": "2025-03-25T19:34:10.388019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ],
   "id": "babc722fd61f5a4f",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T19:34:11.328184Z",
     "start_time": "2025-03-25T19:34:11.312972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statystyki\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc"
   ],
   "id": "406b0d08cbe22a18",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-03-25T19:34:12.691997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_loader, criterion, device)\n",
    "    \n",
    "    print(f\"Epoch [{epoch}/{epochs}]\"\n",
    "          f\" | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\"\n",
    "          f\" | Val Loss: {valid_loss:.4f} | Val Acc: {valid_acc:.4f}\")"
   ],
   "id": "2cea8b8f16b13c05",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T19:27:20.869478Z",
     "start_time": "2025-03-25T19:27:14.930359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")"
   ],
   "id": "e86e213444d3dd36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0825, Test Acc: 0.9794\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "torch.save(model.state_dict(), \"fruits_cnn.pth\")\n",
    "\n",
    "# wczytanie (w nowej sesji lub innym skrypcie)\n",
    "model = SimpleCNN(num_classes)\n",
    "model.load_state_dict(torch.load(\"fruits_cnn.pth\", map_location=device))\n",
    "model.to(device)\n",
    "model.eval()"
   ],
   "id": "c6d1d904db1830fc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

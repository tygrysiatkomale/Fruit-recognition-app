{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-22T08:13:42.065605Z",
     "start_time": "2025-04-22T08:13:42.048678Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import random\n",
    "\n",
    "writer = SummaryWriter(\"runs/fruits\")\n",
    "\n",
    "# Wykrycie dostępności GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T08:13:42.923830Z",
     "start_time": "2025-04-22T08:13:42.905561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dir = \"100x100_dataset/train\"\n",
    "valid_dir = \"100x100_dataset/val\"\n",
    "test_dir  = \"100x100_dataset/test\""
   ],
   "id": "8d0daf8154a0f05e",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T08:13:43.753843Z",
     "start_time": "2025-04-22T08:13:43.740954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((100, 100)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),  # mean (R,G,B)\n",
    "                         (0.5, 0.5, 0.5))  # std  (R,G,B)\n",
    "])\n",
    "\n",
    "# Zbiór walidacyjny / testowy zwykle bez augmentacji, tylko normalizacja\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((100, 100)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                         (0.5, 0.5, 0.5))\n",
    "])"
   ],
   "id": "661613acfd3a0715",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T08:13:48.133488Z",
     "start_time": "2025-04-22T08:13:47.912411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "full_train = datasets.ImageFolder(root=train_dir, transform=train_transforms)\n",
    "\n",
    "val_frac = 0.2\n",
    "train_len = int((1 - val_frac) * len(full_train))\n",
    "val_len = len(full_train) - train_len\n",
    "\n",
    "train_dataset, valid_dataset = random_split(\n",
    "    full_train, [train_len, val_len],\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "valid_dataset.dataset.transform = test_transforms\n",
    "test_dataset  = datasets.ImageFolder(root=test_dir, transform=test_transforms)"
   ],
   "id": "caeb00450fb94d79",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T08:16:17.368157Z",
     "start_time": "2025-04-22T08:16:17.358838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Liczba klas\n",
    "num_classes   = len(full_train.classes)\n",
    "class_to_idx  = full_train.class_to_idx\n",
    "print(\"Liczba klas:\", num_classes)\n",
    "print(\"Klasy (index -> nazwa):\", class_to_idx)"
   ],
   "id": "6f105424922468d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba klas: 66\n",
      "Klasy (index -> nazwa): {'Apple': 0, 'Apricot': 1, 'Avocado': 2, 'Banana': 3, 'Blackberry': 4, 'Blueberry': 5, 'Cabbage': 6, 'Cactus': 7, 'Cantaloupe': 8, 'Carambula': 9, 'Carrot': 10, 'Cauliflower': 11, 'Cherry': 12, 'Chestnut': 13, 'Clementine': 14, 'Cocos': 15, 'Corn': 16, 'Corn Husk': 17, 'Cucumber': 18, 'Dates': 19, 'Eggplant': 20, 'Ginger Root': 21, 'Gooseberry': 22, 'Granadilla': 23, 'Grape Blue': 24, 'Grape White': 25, 'Grapefruit Pink': 26, 'Grapefruit White': 27, 'Guava': 28, 'Hazelnut': 29, 'Kaki': 30, 'Kiwi': 31, 'Kohlrabi': 32, 'Kumquats': 33, 'Lemon Meyer': 34, 'Mandarine': 35, 'Mango Red': 36, 'Mangostan': 37, 'Nectarine Flat': 38, 'Nut Forest': 39, 'Nut Pecan': 40, 'Onion Red': 41, 'Orange': 42, 'Papaya': 43, 'Passion Fruit': 44, 'Peach': 45, 'Peach Flat': 46, 'Pear': 47, 'Pepino': 48, 'Pepper Green': 49, 'Pepper Red': 50, 'Pepper Yellow': 51, 'Physalis': 52, 'Pistachio': 53, 'Plum': 54, 'Pomelo Sweetie': 55, 'Potato Red': 56, 'Potato White': 57, 'Quince': 58, 'Rambutan': 59, 'Redcurrant': 60, 'Salak': 61, 'Strawberry': 62, 'Tangelo': 63, 'Tomato': 64, 'Watermelon': 65}\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T08:16:20.359248Z",
     "start_time": "2025-04-22T08:16:20.324733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 100 -> 50\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 50 -> 25\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)   # 25 -> ~12\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 12 * 12, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN(num_classes).to(device)\n",
    "print(model)"
   ],
   "id": "ed440f6452076193",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=18432, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=66, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T08:16:22.498414Z",
     "start_time": "2025-04-22T08:16:22.488237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', \n",
    "                              factor=0.3, patience=2, verbose=True)\n",
    "early_patience = 5\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs_no_improve = 0"
   ],
   "id": "babc722fd61f5a4f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\agh\\Podstawy-sztucznej-inteligencji\\.venv\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T08:16:24.568374Z",
     "start_time": "2025-04-22T08:16:24.558769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statystyki\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc"
   ],
   "id": "406b0d08cbe22a18",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T09:28:05.314996Z",
     "start_time": "2025-04-22T08:16:26.316267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 20\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc     = evaluate(model, valid_loader, criterion, device)\n",
    "\n",
    "    # TensorBoard + log na konsolę\n",
    "    writer.add_scalars(\"Loss\", {\"train\": train_loss, \"val\": val_loss}, epoch)\n",
    "    writer.add_scalars(\"Acc\",  {\"train\": train_acc,  \"val\": val_acc},  epoch)\n",
    "    writer.flush()\n",
    "    print(f\"Ep {epoch:02d} | \"\n",
    "          f\"train {train_loss:.3f}/{train_acc:.3f} | \"\n",
    "          f\"val {val_loss:.3f}/{val_acc:.3f} | \"\n",
    "          f\"LR {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "    # scheduler LR\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # early‑stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), \"best.pth\")   # zapisz najlepszy\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= early_patience:\n",
    "            print(\"⏹️  Early stopping – koniec uczenia.\")\n",
    "            break"
   ],
   "id": "2cea8b8f16b13c05",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 01 | train 0.738/0.792 | val 0.033/0.992 | LR 1.00e-03\n",
      "Ep 02 | train 0.121/0.963 | val 0.011/0.997 | LR 1.00e-03\n",
      "Ep 03 | train 0.078/0.976 | val 0.009/0.997 | LR 1.00e-03\n",
      "Ep 04 | train 0.070/0.978 | val 0.006/0.999 | LR 1.00e-03\n",
      "Ep 05 | train 0.046/0.986 | val 0.004/0.998 | LR 1.00e-03\n",
      "Ep 06 | train 0.038/0.987 | val 0.003/0.999 | LR 1.00e-03\n",
      "Ep 07 | train 0.047/0.987 | val 0.003/1.000 | LR 1.00e-03\n",
      "Ep 08 | train 0.040/0.988 | val 0.002/1.000 | LR 1.00e-03\n",
      "Ep 09 | train 0.031/0.991 | val 0.002/1.000 | LR 1.00e-03\n",
      "Ep 10 | train 0.039/0.989 | val 0.003/1.000 | LR 1.00e-03\n",
      "Ep 11 | train 0.022/0.994 | val 0.003/1.000 | LR 1.00e-03\n",
      "Ep 12 | train 0.033/0.991 | val 0.001/1.000 | LR 1.00e-03\n",
      "Ep 13 | train 0.024/0.993 | val 0.003/0.999 | LR 1.00e-03\n",
      "Ep 14 | train 0.030/0.992 | val 0.004/0.999 | LR 1.00e-03\n",
      "Ep 15 | train 0.017/0.995 | val 0.003/1.000 | LR 1.00e-03\n",
      "Ep 16 | train 0.009/0.997 | val 0.003/1.000 | LR 3.00e-04\n",
      "Ep 17 | train 0.004/0.999 | val 0.003/1.000 | LR 3.00e-04\n",
      "⏹️  Early stopping – koniec uczenia.\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T09:51:55.283886Z",
     "start_time": "2025-04-22T09:51:46.533404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"train classes:\", len(full_train.classes))\n",
    "print(\"test  classes:\", len(test_dataset.classes))\n",
    "\n",
    "print(\"Różnica test – train:\",\n",
    "      set(test_dataset.classes) - set(full_train.classes))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")"
   ],
   "id": "e86e213444d3dd36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train classes: 66\n",
      "test  classes: 69\n",
      "Różnica test – train: {'Zucchini dark 1', 'Limes 1', 'Zucchini 1', 'Beetroot 1', 'Fig', 'Pomegranate 1', 'Grape Pink 1', 'Mango 1', 'Pitahaya Red 1', 'Strawberry 1', 'Pepper Orange 1', 'Mulberry 1', 'Raspberry 1', 'Potato Sweet 1', 'Beans', 'Walnut 1', 'Maracuja 1', 'Huckleberry 1', 'Tamarillo 1', 'Pineapple 1', 'Lemon 1'}\n"
     ]
    },
    {
     "ename": "UnidentifiedImageError",
     "evalue": "Caught UnidentifiedImageError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"D:\\agh\\Podstawy-sztucznej-inteligencji\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"D:\\agh\\Podstawy-sztucznej-inteligencji\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"D:\\agh\\Podstawy-sztucznej-inteligencji\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"D:\\agh\\Podstawy-sztucznej-inteligencji\\.venv\\lib\\site-packages\\torchvision\\datasets\\folder.py\", line 245, in __getitem__\n    sample = self.loader(path)\n  File \"D:\\agh\\Podstawy-sztucznej-inteligencji\\.venv\\lib\\site-packages\\torchvision\\datasets\\folder.py\", line 284, in default_loader\n    return pil_loader(path)\n  File \"D:\\agh\\Podstawy-sztucznej-inteligencji\\.venv\\lib\\site-packages\\torchvision\\datasets\\folder.py\", line 263, in pil_loader\n    img = Image.open(f)\n  File \"D:\\agh\\Podstawy-sztucznej-inteligencji\\.venv\\lib\\site-packages\\PIL\\Image.py\", line 3532, in open\n    raise UnidentifiedImageError(msg)\nPIL.UnidentifiedImageError: cannot identify image file <_io.BufferedReader name='100x100_dataset/test\\\\Apple\\\\100_100.jpg'>\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnidentifiedImageError\u001B[0m                    Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[56], line 7\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest  classes:\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mlen\u001B[39m(test_dataset\u001B[38;5;241m.\u001B[39mclasses))\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRóżnica test – train:\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      5\u001B[0m       \u001B[38;5;28mset\u001B[39m(test_dataset\u001B[38;5;241m.\u001B[39mclasses) \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mset\u001B[39m(full_train\u001B[38;5;241m.\u001B[39mclasses))\n\u001B[1;32m----> 7\u001B[0m test_loss, test_acc \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTest Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtest_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Test Acc: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtest_acc\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[33], line 37\u001B[0m, in \u001B[0;36mevaluate\u001B[1;34m(model, dataloader, criterion, device)\u001B[0m\n\u001B[0;32m     34\u001B[0m total \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m---> 37\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m images, labels \u001B[38;5;129;01min\u001B[39;00m dataloader:\n\u001B[0;32m     38\u001B[0m         images \u001B[38;5;241m=\u001B[39m images\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     39\u001B[0m         labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32mD:\\agh\\Podstawy-sztucznej-inteligencji\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    705\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    706\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    707\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 708\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    709\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    710\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    711\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[0;32m    712\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    713\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[0;32m    714\u001B[0m ):\n",
      "File \u001B[1;32mD:\\agh\\Podstawy-sztucznej-inteligencji\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1480\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1478\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_task_info[idx]\n\u001B[0;32m   1479\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_rcvd_idx \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m-> 1480\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\agh\\Podstawy-sztucznej-inteligencji\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1505\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._process_data\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m   1503\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_put_index()\n\u001B[0;32m   1504\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, ExceptionWrapper):\n\u001B[1;32m-> 1505\u001B[0m     \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1506\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[1;32mD:\\agh\\Podstawy-sztucznej-inteligencji\\.venv\\lib\\site-packages\\torch\\_utils.py:733\u001B[0m, in \u001B[0;36mExceptionWrapper.reraise\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    729\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m    730\u001B[0m     \u001B[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001B[39;00m\n\u001B[0;32m    731\u001B[0m     \u001B[38;5;66;03m# instantiate since we don't know how to\u001B[39;00m\n\u001B[0;32m    732\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 733\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exception\n",
      "\u001B[1;31mUnidentifiedImageError\u001B[0m: Caught UnidentifiedImageError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"D:\\agh\\Podstawy-sztucznej-inteligencji\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"D:\\agh\\Podstawy-sztucznej-inteligencji\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"D:\\agh\\Podstawy-sztucznej-inteligencji\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"D:\\agh\\Podstawy-sztucznej-inteligencji\\.venv\\lib\\site-packages\\torchvision\\datasets\\folder.py\", line 245, in __getitem__\n    sample = self.loader(path)\n  File \"D:\\agh\\Podstawy-sztucznej-inteligencji\\.venv\\lib\\site-packages\\torchvision\\datasets\\folder.py\", line 284, in default_loader\n    return pil_loader(path)\n  File \"D:\\agh\\Podstawy-sztucznej-inteligencji\\.venv\\lib\\site-packages\\torchvision\\datasets\\folder.py\", line 263, in pil_loader\n    img = Image.open(f)\n  File \"D:\\agh\\Podstawy-sztucznej-inteligencji\\.venv\\lib\\site-packages\\PIL\\Image.py\", line 3532, in open\n    raise UnidentifiedImageError(msg)\nPIL.UnidentifiedImageError: cannot identify image file <_io.BufferedReader name='100x100_dataset/test\\\\Apple\\\\100_100.jpg'>\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T09:46:36.993664Z",
     "start_time": "2025-04-22T09:46:36.986504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "extra = sorted(set(os.listdir(test_dir)) - set(os.listdir(train_dir)))\n",
    "print(\"Foldery obecne TYLKO w teście:\", extra, len(extra))\n",
    "\n",
    "extra = sorted(set(os.listdir(train_dir)) - set(os.listdir(test_dir)))\n",
    "print(\"Foldery obecne TYLKO w trainie:\", extra, len(extra))"
   ],
   "id": "97033d598b446f5e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foldery obecne TYLKO w teście: ['Beans', 'Beetroot 1', 'Fig', 'Grape Pink 1', 'Huckleberry 1', 'Lemon 1', 'Limes 1', 'Mango 1', 'Maracuja 1', 'Mulberry 1', 'Pepper Orange 1', 'Pineapple 1', 'Pitahaya Red 1', 'Pomegranate 1', 'Potato Sweet 1', 'Raspberry 1', 'Strawberry 1', 'Tamarillo 1', 'Walnut 1', 'Zucchini 1', 'Zucchini dark 1'] 21\n",
      "Foldery obecne TYLKO w trainie: ['Cantaloupe', 'Carrot', 'Clementine', 'Cocos', 'Corn', 'Granadilla', 'Grape Blue', 'Guava', 'Mandarine', 'Mango Red', 'Mangostan', 'Nectarine Flat', 'Nut Forest', 'Nut Pecan', 'Orange', 'Papaya', 'Pepper Red', 'Pepper Yellow'] 18\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "torch.save(model.state_dict(), \"fruits_cnn.pth\")\n",
    "\n",
    "# wczytanie (w nowej sesji lub innym skrypcie)\n",
    "model = SimpleCNN(num_classes)\n",
    "model.load_state_dict(torch.load(\"fruits_cnn.pth\", map_location=device))\n",
    "model.to(device)\n",
    "model.eval()"
   ],
   "id": "c6d1d904db1830fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T10:26:59.131915Z",
     "start_time": "2025-04-22T10:26:59.120840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "merge_map = {\n",
    "    r'^Apple': 'Apple',\n",
    "    r'^Apricot': 'Apricot',\n",
    "    r'^Avocado': 'Avocado',\n",
    "    r'^Banana': 'Banana',\n",
    "    r'^Blackberrie': 'Blackberry',\n",
    "    r'^Blueberry': 'Blueberry',\n",
    "    r'^Cabbage': 'Cabbage',\n",
    "    r'^Cactus': 'Cactus',\n",
    "    r'^Cantaloupe': 'Cantaloupe',\n",
    "    r'^Carambula': 'Carambula',\n",
    "    r'^Carrot': 'Carrot',\n",
    "    r'^Cauliflower': 'Cauliflower',\n",
    "    r'^Cherry': 'Cherry',\n",
    "    r'^Chestnut': 'Chestnut',\n",
    "    r'^Clementine': 'Clementine',\n",
    "    r'^Cocos': 'Cocos',\n",
    "    r'^Corn Husk': 'Corn Husk',\n",
    "    r'^Corn': 'Corn',\n",
    "    r'^Cucumber': 'Cucumber',\n",
    "    r'^Dates': 'Dates',\n",
    "    r'^Eggplant': 'Eggplant',\n",
    "    r'^Ginger Root': 'Ginger Root',\n",
    "    r'^Gooseberry': 'Gooseberry',\n",
    "    r'^Granadilla': 'Granadilla',\n",
    "    r'^Grape Blue': 'Grape Blue',\n",
    "    r'^Grape White': 'Grape White',\n",
    "    r'^Grape Pink': 'Grape Pink',\n",
    "    r'^Grapefruit Pink': 'Grapefruit Pink',\n",
    "    r'^Grapefruit White': 'Grapefruit White',\n",
    "    r'^Guava': 'Guava',\n",
    "    r'^Hazelnut': 'Hazelnut',\n",
    "    r'^Kaki': 'Kaki',\n",
    "    r'^Kiwi': 'Kiwi',\n",
    "    r'^Kohlrabi': 'Kohlrabi',\n",
    "    r'^Kumquats': 'Kumquats',\n",
    "    r'^Pineapple': 'Pineapple',\n",
    "    r'^Lemon': 'Lemon',\n",
    "    r'^Mandarine': 'Mandarine',\n",
    "    r'^Mango': 'Mango',\n",
    "    r'^Mangostan': 'Mangostan',\n",
    "    r'^Nectarine Flat': 'Nectarine Flat',\n",
    "    r'^Nut Forest': 'Nut Forest',\n",
    "    r'^Nut Pecan': 'Nut Pecan',\n",
    "    r'^Onion Red': 'Onion Red',\n",
    "    r'^Orange': 'Orange',\n",
    "    r'^Papaya': 'Papaya',\n",
    "    r'^Passion Fruit': 'Passion Fruit',\n",
    "    r'^Peach Flat': 'Peach Flat',\n",
    "    r'^Peach': 'Peach',\n",
    "    r'^Pear': 'Pear',\n",
    "    r'^Pepino': 'Pepino',\n",
    "    r'^Pepper Green': 'Pepper Green',\n",
    "    r'^Pepper Red': 'Pepper Red',\n",
    "    r'^Pepper Yellow': 'Pepper Yellow',\n",
    "    r'^Pepper Orange': 'Pepper Orange',\n",
    "    r'^Physalis with Husk': 'Physalis',\n",
    "    r'^Physalis': 'Physalis',\n",
    "    r'^Pistachio': 'Pistachio',\n",
    "    r'^Plum': 'Plum',\n",
    "    r'^Mulberry': 'Mulberry',\n",
    "    r'^Limes': 'Lime',\n",
    "    r'^Pitahaya': 'Pitahaya',\n",
    "    r'^Maracuja': 'Maracuja',\n",
    "    r'^Pomegranate': 'Pomegranate',\n",
    "    r'^Pomelo Sweetie': 'Pomelo Sweetie',\n",
    "    r'^Potato Red Washed': 'Potato Red',\n",
    "    r'^Potato Red': 'Potato Red',\n",
    "    r'^Potato Sweet': 'Potato Sweet',\n",
    "    r'^Potato White': 'Potato White',\n",
    "    r'^Quince': 'Quince',\n",
    "    r'^Rambutan': 'Rambutan',\n",
    "    r'^Tamarillo': 'Tamarillo',\n",
    "    r'^Redcurrant': 'Redcurrant',\n",
    "    r'^Salak': 'Salak',\n",
    "    r'^Strawberry': 'Strawberry',\n",
    "    r'^Raspberry': 'Raspberry',\n",
    "    r'^Tangelo': 'Tangelo',\n",
    "    r'^Tomato Heart': 'Tomato',\n",
    "    r'^Tomato not Ripened': 'Tomato',\n",
    "    r'^Tomato': 'Tomato',\n",
    "    r'^Watermelon': 'Watermelon',\n",
    "    r'^Beans': 'Beans',\n",
    "    r'^Walnut': 'Walnut',\n",
    "    r'^Fig': 'Fig',\n",
    "    r'^Beetroot': 'Beetroot',\n",
    "    r'^Huckleberry': 'Huckleberry',\n",
    "    r'^Zucchini': 'Zucchini',\n",
    "    r'^Durian': 'Durian'\n",
    "}"
   ],
   "id": "950f2980c56c4ea5",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T10:28:33.917766Z",
     "start_time": "2025-04-22T10:27:03.522473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def map_class(folder_name):\n",
    "    for pattern, general_name in merge_map.items():\n",
    "        if re.match(pattern, folder_name):\n",
    "            return general_name\n",
    "    return folder_name\n",
    "\n",
    "source_dirs = {\n",
    "    'train': 'fruits-360_100x100/fruits-360/Training',\n",
    "    # 'val': 'drive/MyDrive/content/fruits-360_original_100_30_20_test/test_val',\n",
    "    # 'test': 'fruits-360_100x100/fruits-360/Test'\n",
    "}\n",
    "\n",
    "target_root = '100x100_dataset'\n",
    "\n",
    "for split, source_dir in source_dirs.items():\n",
    "    for class_folder in os.listdir(source_dir):\n",
    "        class_path = os.path.join(source_dir, class_folder)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        new_class = map_class(class_folder)\n",
    "        target_class_dir = os.path.join(target_root, split, new_class)\n",
    "        os.makedirs(target_class_dir, exist_ok=True)\n",
    "\n",
    "        for img_file in os.listdir(class_path):\n",
    "            src = os.path.join(class_path, img_file)\n",
    "            dst = os.path.join(target_class_dir, img_file)\n",
    "            shutil.copy2(src, dst)\n",
    "\n",
    "print(\"✅ Gotowe! Nowy zbiór utworzony w:\", target_root)"
   ],
   "id": "cc87ac8a718bce6e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Gotowe! Nowy zbiór utworzony w: 100x100_dataset\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T10:29:05.235576Z",
     "start_time": "2025-04-22T10:29:02.826775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def count_images_in_subfolders(root_dir):\n",
    "    \"\"\"\n",
    "    Dla każdego bezpośredniego podfolderu w root_dir\n",
    "    wypisuje nazwę folderu i liczbę plików w nim.\n",
    "    \"\"\"\n",
    "    for name in os.listdir(root_dir):\n",
    "        subpath = os.path.join(root_dir, name)\n",
    "        if os.path.isdir(subpath):\n",
    "            # liczymy wszystkie pliki (nie foldery) w subpath\n",
    "            count = sum(\n",
    "                1 for fname in os.listdir(subpath)\n",
    "                if os.path.isfile(os.path.join(subpath, fname))\n",
    "            )\n",
    "            print(f\"{name}: {count}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = \"100x100_dataset/train\"\n",
    "    count_images_in_subfolders(root)"
   ],
   "id": "2a5d2df5a09ea158",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple: 1610\n",
      "Apricot: 656\n",
      "Avocado: 657\n",
      "Banana: 1134\n",
      "Beans: 77\n",
      "Beetroot: 150\n",
      "Blackberry: 675\n",
      "Blueberry: 616\n",
      "Cabbage: 193\n",
      "Cactus: 893\n",
      "Cantaloupe: 250\n",
      "Carambula: 234\n",
      "Carrot: 151\n",
      "Cauliflower: 936\n",
      "Cherry: 1072\n",
      "Chestnut: 603\n",
      "Clementine: 490\n",
      "Cocos: 490\n",
      "Corn: 450\n",
      "Corn Husk: 616\n",
      "Cucumber: 1514\n",
      "Dates: 656\n",
      "Eggplant: 864\n",
      "Fig: 234\n",
      "Ginger Root: 396\n",
      "Gooseberry: 620\n",
      "Granadilla: 490\n",
      "Grape Blue: 984\n",
      "Grape Pink: 164\n",
      "Grape White: 656\n",
      "Grapefruit Pink: 656\n",
      "Grapefruit White: 656\n",
      "Guava: 490\n",
      "Hazelnut: 621\n",
      "Huckleberry: 166\n",
      "Kaki: 656\n",
      "Kiwi: 622\n",
      "Kohlrabi: 628\n",
      "Kumquats: 370\n",
      "Lemon: 656\n",
      "Lime: 166\n",
      "Mandarine: 490\n",
      "Mango: 541\n",
      "Maracuja: 166\n",
      "Mulberry: 164\n",
      "Nectarine Flat: 480\n",
      "Nut Forest: 654\n",
      "Nut Pecan: 534\n",
      "Onion Red: 600\n",
      "Orange: 479\n",
      "Papaya: 492\n",
      "Passion Fruit: 416\n",
      "Peach: 994\n",
      "Peach Flat: 656\n",
      "Pear: 1259\n",
      "Pepino: 656\n",
      "Pepper Green: 592\n",
      "Pepper Orange: 234\n",
      "Pepper Red: 250\n",
      "Pepper Yellow: 666\n",
      "Physalis: 652\n",
      "Pineapple: 166\n",
      "Pistachio: 930\n",
      "Pitahaya: 166\n",
      "Plum: 606\n",
      "Pomegranate: 164\n",
      "Pomelo Sweetie: 603\n",
      "Potato Red: 604\n",
      "Potato Sweet: 150\n",
      "Potato White: 600\n",
      "Quince: 656\n",
      "Rambutan: 656\n",
      "Raspberry: 166\n",
      "Redcurrant: 656\n",
      "Salak: 652\n",
      "Strawberry: 993\n",
      "Tamarillo: 166\n",
      "Tangelo: 656\n",
      "Tomato: 984\n",
      "Walnut: 249\n",
      "Watermelon: 632\n",
      "Zucchini: 80\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T10:32:02.300698Z",
     "start_time": "2025-04-22T10:31:52.915246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "# >>> 1. ustawienia <<< --------------------------------------------------------\n",
    "DATA_ROOT = Path(\"100x100_dataset\")          # katalog z danymi\n",
    "TRAIN_DIR = DATA_ROOT / \"train\"              # obecny zbiór (same obrazki)\n",
    "VAL_DIR   = DATA_ROOT / \"val\"\n",
    "TEST_DIR  = DATA_ROOT / \"test\"\n",
    "VAL_FRACTION  = 0.15                         # 15 % walidacja\n",
    "TEST_FRACTION = 0.15                         # 15 % test\n",
    "RANDOM_SEED   = 42                           # powtarzalność\n",
    "\n",
    "# >>> 2. przygotuj katalogi <<< ------------------------------------------------\n",
    "for target_dir in (VAL_DIR, TEST_DIR):\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# >>> 3. losowy, stratyfikowany podział <<< -----------------------------------\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "for class_dir in TRAIN_DIR.iterdir():\n",
    "    if not class_dir.is_dir():\n",
    "        continue\n",
    "\n",
    "    images = sorted(class_dir.glob(\"*\"))            # lista ścieżek\n",
    "    random.shuffle(images)\n",
    "\n",
    "    n_total = len(images)\n",
    "    n_val   = math.ceil(n_total * VAL_FRACTION)\n",
    "    n_test  = math.ceil(n_total * TEST_FRACTION)\n",
    "\n",
    "    # ── 3a. utwórz katalogi klas w val/test ───────────────────────────────────\n",
    "    (VAL_DIR  / class_dir.name).mkdir(parents=True, exist_ok=True)\n",
    "    (TEST_DIR / class_dir.name).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # ── 3b. przenieś pliki ────────────────────────────────────────────────────\n",
    "    for i, img_path in enumerate(images):\n",
    "        if i < n_val:\n",
    "            dst = VAL_DIR  / class_dir.name / img_path.name\n",
    "        elif i < n_val + n_test:\n",
    "            dst = TEST_DIR / class_dir.name / img_path.name\n",
    "        else:\n",
    "            continue  # zostaje w TRAIN_DIR\n",
    "        shutil.move(img_path, dst)\n",
    "\n",
    "print(\"✅  Zbiory utworzone — możesz trenować model.\")\n"
   ],
   "id": "98cc5de1daa8168f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Zbiory utworzone — możesz trenować model.\n"
     ]
    }
   ],
   "execution_count": 72
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
